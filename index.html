
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<title>ICML workshop on Theoretic Foundation, Criticism, and Application Trend of Explainable AI</title>
<META NAME="DESCRIPTION" CONTENT="ICML workshop, Theoretic Foundation, Criticism, and Application Trend of Explainable AI">

<!-- <link rel="shortcut icon" type="image/x-icon" href="figures/logo.ico" /> -->
<link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/bootstrap/3.2.0/css/bootstrap.min.css">
<link href='http://fonts.googleapis.com/css?family=Lato:400,700' rel='stylesheet' type='text/css'>
<link href="css/style.css" rel="stylesheet" type="text/css" />

<meta property="og:type" content="ICML-21 Workshop on Theoretic Foundation, Criticism, and Application Trend of Explainable AI" />
<meta property="og:title" content="ICML-21 Workshop on Theoretic Foundation, Criticism, and Application Trend of Explainable AI">
<meta property="og:description" content="ICML-21 Workshop on Theoretic Foundation, Criticism, and Application Trend of Explainable AI">
<meta property="og:image" content="https://icml2021-xai.github.io/figures/rsz_logo.jpg">
<meta property="og:url" content="https://icml2021-xai.github.io/">

<div id='wx_logo' style='display:none;'>
  <img src='figures/rsz_logo.jpg' />
</div>

</head>

<body>
<div class="container">
  <table border="0" align="center">
    <tr>
      <td width="700" align="center" valign="middle"><h3>ICML 2021 Workshop on</h3>
      <span class="title">Theoretic Foundation, Criticism, and Application Trend of Explainable AI</span></td>
    </tr>
<!--     <tr> -->
<!--         <td colspan="3" align="center"><h3>July 2020 @ Yokohama, Japan</h3></td> -->
<!--     </tr> -->
  </table>
  <!-- <p><img src="figures/main.png" width="1000" align="middle" /></p> -->
</div>

</br>

<div class="container">
  <h2>Overview</h2>
    <div class="overview">
        <p>Deep neural networks (DNNs) have undoubtedly brought great success to a wide range of applications in computer vision, computational linguistics, and AI. However, foundational principles underlying the DNNs’ success and their resilience to adversarial attacks are still largely missing. Interpreting and theorizing the internal mechanisms of DNNs becomes a compelling yet controversial topic.</p>

        <p>Unlike previous workshops or tutorials on explainable AI (XAI), the proposed workshop pays a special interests in theoretic foundations, limitations, and new application trends in the scope of XAI. These issues reflect new bottlenecks in the future development of XAI, for example: (1) no theoretic definition of XAI and no solid and widely-used formulation for even a specific explanation task. (2) No sophisticated formulation of the essence of “semantics” encoded in a DNN. (3) How to bridge the gap between connectionism and symbolism in AI research has not been sophisticatedly explored. (4) How to evaluate the correctness and trustworthiness of an explanation result is still an open problem. (5) How to bridge the intuitive explanation (e.g., the attribution/importance-based explanation) and a DNN’s representation capacity (e.g., the generalization power) is still a significant challenge. (6) Using the explanation to guide the architecture design or substantially boost the performance of a DNN is a bottleneck.</p>
    
        <p>Therefore, this workshop aims to bring together researchers, engineers as well as industrial practitioners, who concern about the interpretability, safety, and reliability of artificial intelligence. In this workshop, we hope to use a broad discussion on the above bottleneck issues to explore new critical and constructive views of the future development of XAI. Research outcomes are also expected to profoundly influences critical industrial applications such as medical diagnosis, finance, and autonomous driving.</p>
  </div>
</div>

</br>

<div class="container">
  <h2>Schedule</h2>
      <h3>xxx xxx, 2021 </h3>
      <h3>ZOOM: xxx </h3>
      <center>
      <table cellspacing="50">
        <tr>
          <td align="center"><font size="4.5"> 08:40 - 08:45 </font></td>
          <td align="center"><strong><font size="4.5"> Welcome </font></strong></td>
        </tr>
        <tr>
          <td align="center"><font size="4.5"> 08:45 - 09:15 </font></td>
          <td align="center"><font size="4.5"> 	Invited talk: Dr. Song-Chun Zhu - xxx(title) </font></td>
        </tr>
        <tr>
          <td align="center"><font size="4.5"> 08:45 - 09:15 </font></td>
          <td align="center"><font size="4.5"> 	Invited talk: Dr. Song-Chun Zhu - xxx(title) </font></td>
        </tr>
        <tr>
          <td align="center"><font size="4.5"> 08:45 - 09:15 </font></td>
          <td align="center"><font size="4.5"> 	Invited talk: Dr. Song-Chun Zhu - xxx(title) </font></td>
        </tr>
        <tr>
          <td align="center"><font size="4.5"> 08:45 - 09:15 </font></td>
          <td align="center"><font size="4.5"> 	Invited talk: Dr. Song-Chun Zhu - xxx(title) </font></td>
        </tr>
        <tr>
          <td align="center"><font size="4.5"> 08:45 - 09:15 </font></td>
          <td align="center"><font size="4.5"> 	Invited talk: Dr. Song-Chun Zhu - xxx(title) </font></td>
        </tr>
        <tr>
          <td align="center"><font size="4.5"> 08:45 - 09:15 </font></td>
          <td align="center"><font size="4.5"> 	Invited talk: Dr. Song-Chun Zhu - xxx(title) </font></td>
        </tr>
        <tr>
          <td align="center"><font size="4.5"> 08:45 - 09:15 </font></td>
          <td align="center"><strong><font size="4.5"> 	Poster Session </font></strong></td>
        </tr>
        </table>
      </center>
</div>

</br>

<div class="container">
  <h2>Topics</h2>
    <div class="Topics">
      <p> Topics of interests include, but are not limited to, following fields: </p>
      <ul>
      <li> XAI theories</li>
      <li> Critical and constructive commentary on XAI, e.g., limitations of the current XAI techniques.</li>
      <li> Qualitative and quantitative diagnosis and analysis of the XAI systems.</li>
      <li> Deep coupling of neural networks and grammars or graphical models</li>
      <li> Probabilistic logic programming, causality reasoning and learning.</li>
      <li> Safety, adversarial attacking and defense of DNNs.</li>
      <li> Industrial applications of trustworthy AI, e.g. in medical diagnosis, autonomous driving, and finance.</li>
      </ul>
      <p> All above topics are core issues in the development of explainable AI and have received increasing attention in recent years. We believe the workshop would be of broad interest to the ICML community</p>
    </div>
</div>

</br>
  
<div class="container">
  <h2>Organizers</h2>
    <div>
      <div class="instructor">
        <a href="http://qszhang.com/" >
      <div class="instructorphoto"><img src="figures/QuanshiZhang-min.jpg"></div>
      <div>Quanshi Zhang<br><font size="2.5">@ John Hopcroft Center</font><br><font size="2.5">Shanghai Jiao Tong University</font></div>
      </a>
     </div>

     <div class="instructor">
      <a href="https://sites.google.com/view/zhanxingzhu/">
          <div class="instructorphoto"><img src="figures/zhanxingzhu-min.jpg"></div>
          <div><br>Zhanxing Zhu<br><font size="2.5"> </font> <br> <font size="2.5"> </font></div>
      </a>
    </div>

    </div>
    <p></p>
</div>

</br>


</br>

<div class="containersmall">
  <p>Please contact <a href="mailto:zqs1022@sjtu.edu.cn">Quanshi Zhang</a> if you have questions.</p>
</div>

<!--<p align="center" class="acknowledgement">Last updated: Jan. 6, 2017</p>-->
</body>
</html>
